<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="initial-scale=1, width=device-width" />

    <link rel="stylesheet" href="./global.css" />
    <link rel="stylesheet" href="./reflections.css" />
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Work Sans:wght@400;600;700&display=swap"
    />
    <link
      rel="stylesheet"
      href="https://fonts.googleapis.com/css2?family=Inter:wght@600;900&display=swap"
    />
  </head>
  <body>
    <div class="reflections">
      <div class="cs1102-project-topic2">
        CS1102 PROJECT TOPIC - THE DEVELOPMENT OF NEURAL NETWORKS
      </div>
      <div class="reflections-child"></div>
      <img class="cicles-icon2" alt="" src="./public/cicles.svg" />
      <button class="button">
        <div class="button1">Reflections</div>
      </button>
      <button class="button4" id="button3">
        <div class="button5">Try It Out</div>
      </button>
      <button class="button2" id="button2">
        <div class="button1">Home</div>
      </button>
        <div class="body1">
        <b class="introduction1">Introduction</b>
        <b class="exploring-mlps-and-container">
          <p class="exploring-mlps-and">Exploring MLPs and CNNs:</p>
        </b>
        <b class="unveiling-loopholes-in">Unveiling 'Loopholes' in CNN:</b>
        <b class="the-case-for-container">
          <span class="the-case-for-container1">
            <p class="exploring-mlps-and">The Case for Explainable AI:</p>
          </span>
        </b>
        <b class="benefits-of-explainable-container">
          <span class="the-case-for-container1">
            <p class="exploring-mlps-and">Benefits of Explainable AI:</p>
          </span>
        </b>
        <div class="as-the-field">
          As the field of artificial intelligence continues to advance, neural
          networks have gained significant prominence, particularly MLP and CNN.
          Intrigued by their potential, our team embarked on a journey to
          explore the intricacies of these neural networks. However, as we
          delved deeper, we encountered a myriad of challenges inherent in these
          models.
        </div>
        <div class="initially-drawn-to-container">
          <span class="the-case-for-container1">
            <p class="exploring-mlps-and">
              Initially drawn to MLP and CNN due to their widespread adoption
              and success in various domains, we soon realized the limitations
              and ethical concerns associated with them. Despite their
              remarkable performance in tasks like image classification and
              pattern recognition, we uncovered issues such as biases, lack of
              interpretability, and the potential for misuse and manipulation.
              These shortcomings raised crucial questions about the ethical
              implications of relying solely on these models for
              decision-making.
            </p>
          </span>
        </div>
        <div class="in-our-pursuit">
          In our pursuit of enhancing model performance and mitigating biases,
          we turned to CNN, hoping to find solutions to the challenges posed by
          MLP. While CNNs demonstrated improved accuracy and robustness in
          certain tasks, we encountered unexpected 'loopholes' that threatened
          the integrity of our findings. One notable example was the infamous
          incident where a CNN misclassified images of gorillas as African
          American individuals, highlighting the model's susceptibility to
          erroneous judgments.
        </div>
        <div class="faced-with-the-container">
          <span class="the-case-for-container1">
            <p class="exploring-mlps-and">
              Faced with the complexities and ethical dilemmas inherent in
              neural networks, we firmly advocate for the integration of
              Explainable AI (XAI) principles into these systems. By
              incorporating XAI techniques, such as feature importance analysis,
              local explanations, and interactive visualizations, we believe we
              can address the shortcomings of MLP and CNN while fostering
              transparency and accountability in AI decision-making processes.
            </p>
          </span>
        </div>
        <div class="transparency-xai-provides-container">
          <ul class="transparency-xai-provides-val">
            <li class="transparency-xai-provides">
              Transparency: XAI provides valuable insights into the
              decision-making process of neural networks, enabling stakeholders
              to understand how and why certain outcomes are reached.
            </li>
            <li class="transparency-xai-provides">
              Interpretability: By generating interpretable explanations, XAI
              empowers users to trust and verify the decisions made by AI
              systems, thereby enhancing their acceptance and usability.
            </li>
            <li class="transparency-xai-provides">
              Bias Mitigation: XAI techniques can effectively identify and
              mitigate biases present in neural network models, promoting
              fairness and equity in decision-making.
            </li>
            <li>
              Robustness: By uncovering vulnerabilities and 'loopholes' in
              neural network models, XAI plays a crucial role in improving model
              robustness and reliability.
            </li>
          </ul>
        </div>
        <div class="in-conclusion-our-container">
          <span class="the-case-for-container1">
            <ul class="transparency-xai-provides-val">
              <li>
                In conclusion, our exploration of neural networks has
                underscored the critical need for Explainable AI in enhancing
                the transparency, interpretability, and ethical integrity of AI
                systems. By embracing XAI principles, we can navigate the
                complexities of neural networks while striving for more
                accountable and trustworthy AI solutions.
              </li>
            </ul>
          </span>
        </div>
      </div>
    </div>
    <script>
      var button3 = document.getElementById("button3");
      if (button3) {
        button3.addEventListener("click", function (e) {
          window.location.href = "http://172.28.190.193:8502/";
        });
      }
      
      var button2 = document.getElementById("button2");
      if (button2) {
        button2.addEventListener("click", function (e) {
          window.location.href = "./index.html";
        });
      }
      </script>
  </body>
</html>
